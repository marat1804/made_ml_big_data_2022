{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de984d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.output_area pre {\n",
       "   white-space: pre;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " %%html\n",
    "<style>\n",
    "div.output_area pre {\n",
    "    white-space: pre;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b38863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.prompt { min-width:10ex !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>div#notebook { font-size:14px !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML, clear_output\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "display(HTML(\"<style>.prompt { min-width:10ex !important; }</style>\"))\n",
    "display(HTML(\"<style>div#notebook { font-size:14px !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9bd698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4665af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb619f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f84f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-6GA3S22:4050\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x19ad996d6a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6fb67",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a143b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv(\n",
    "    'train.csv',\n",
    "    header=True,\n",
    "    multiLine=True,\n",
    "    ignoreLeadingWhiteSpace=True,\n",
    "    ignoreTrailingWhiteSpace=True,\n",
    "    encoding=\"utf-8\",\n",
    "    sep=\",\",\n",
    "    quote='\"',\n",
    "    escape='\"',\n",
    "    inferSchema=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44af6875",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.csv(\n",
    "    'test.csv',\n",
    "    header=True,\n",
    "    multiLine=True,\n",
    "    ignoreLeadingWhiteSpace=True,\n",
    "    ignoreTrailingWhiteSpace=True,\n",
    "    encoding=\"utf-8\",\n",
    "    sep=\",\",\n",
    "    quote='\"',\n",
    "    escape='\"',\n",
    "    inferSchema=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cd52b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = spark.read.csv(\n",
    "    'test_labels.csv',\n",
    "    header=True,\n",
    "    multiLine=True,\n",
    "    ignoreLeadingWhiteSpace=True,\n",
    "    ignoreTrailingWhiteSpace=True,\n",
    "    encoding=\"utf-8\",\n",
    "    sep=\",\",\n",
    "    quote='\"',\n",
    "    escape='\"',\n",
    "    inferSchema=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56a8e9",
   "metadata": {},
   "source": [
    "### See data details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c745e6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61e90dff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+-------------------+--------------------+-----------------+--------------------+-------------------+-------------------+\n",
      "|summary|id              |toxic              |severe_toxic        |obscene          |threat              |insult             |identity_hate      |\n",
      "+-------+----------------+-------------------+--------------------+-----------------+--------------------+-------------------+-------------------+\n",
      "|count  |159571          |159571             |159571              |159571           |159571              |159571             |159571             |\n",
      "|mean   |Infinity        |0.09584448302009764|0.009995550569965721|0.052948217407925|0.002995531769557125|0.04936360616904074|0.00880485802558109|\n",
      "|stddev |NaN             |0.2943787715999705 |0.09947714085748408 |0.223930832915411|0.05464958623142267 |0.2166267172768179 |0.09342048594149767|\n",
      "|min    |0000997932d777bf|0                  |0                   |0                |0                   |0                  |0                  |\n",
      "|max    |ffffc2f890bb6fb5|1                  |1                   |1                |1                   |1                  |1                  |\n",
      "+-------+----------------+-------------------+--------------------+-----------------+--------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.drop('comment_text').describe().show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e1bae25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test = (\n",
    "    test\n",
    "    .join(\n",
    "        test_labels,\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "    .where(F.col('toxic') != -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4ed246d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63978"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d133094e",
   "metadata": {},
   "source": [
    "### Hashing TF with 100 numFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "54b880e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e42733aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"comment_text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "# стоп-слова\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"]\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "de5d68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=100)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4325141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {}\n",
    "predicted = {}\n",
    "label_columns = [\n",
    "    'toxic',\n",
    "    'severe_toxic',\n",
    "    'obscene',\n",
    "    'threat',\n",
    "    'insult',\n",
    "    'identity_hate',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "553faab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in label_columns:\n",
    "    train = train.withColumn(col, F.col(col).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d7b81451",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in label_columns:\n",
    "    all_test = all_test.withColumn(col, F.col(col).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "da02bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit = pipeline.fit(train)\n",
    "train_df = pipelineFit.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f2650b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pipelineFit.transform(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dfef8cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing toxic\n",
      "Processing severe_toxic\n",
      "Processing obscene\n",
      "Processing threat\n",
      "Processing insult\n",
      "Processing identity_hate\n"
     ]
    }
   ],
   "source": [
    "for col in label_columns:\n",
    "    print(f'Processing {col}')\n",
    "    lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0,\n",
    "                            featuresCol='features', labelCol=col, predictionCol=f'{col}_pred', \n",
    "                            rawPredictionCol=f'raw_{col}_pred', probabilityCol=f'{col}_prob')\n",
    "    lrModel = lr.fit(train_df)\n",
    "\n",
    "    test_df = lrModel.transform(test_df)\n",
    "    predicted[col] = test_df\n",
    "    all_models[col] = lrModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d4044fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = [col for col in test_df.columns if 'pred' in col and 'raw' not in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b6d81a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+---------------------+--------------------+-----------+--------------------+------------------+\n",
      "|summary|toxic_pred           |severe_toxic_pred    |obscene_pred        |threat_pred|insult_pred         |identity_hate_pred|\n",
      "+-------+---------------------+---------------------+--------------------+-----------+--------------------+------------------+\n",
      "|count  |63978                |63978                |63978               |63978      |63978               |63978             |\n",
      "|mean   |4.5328081528025257E-4|4.6891118822095096E-5|1.71934102347682E-4 |0.0        |1.406733564662853E-4|0.0               |\n",
      "|stddev |0.02128573310060443  |0.006847601985208643 |0.013111339671681809|0.0        |0.011859838362100266|0.0               |\n",
      "|min    |0.0                  |0.0                  |0.0                 |0.0        |0.0                 |0.0               |\n",
      "|max    |1.0                  |1.0                  |1.0                 |0.0        |1.0                 |0.0               |\n",
      "+-------+---------------------+---------------------+--------------------+-----------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.select(*pred_cols).describe().show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4cd98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b9dba762",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f0b81a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in label_columns:\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=f'raw_{col}_pred', labelCol=col)\n",
    "    metrics[col] = evaluator.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4eaccbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxic': 0.7541931801265525,\n",
       " 'severe_toxic': 0.8575037811781477,\n",
       " 'obscene': 0.7582951685942847,\n",
       " 'threat': 0.8149224698894523,\n",
       " 'insult': 0.754035473968106,\n",
       " 'identity_hate': 0.7485780454524604}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3150cac",
   "metadata": {},
   "source": [
    "### Hashing TF with 1000 numFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cc1dbb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "84113556",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {}\n",
    "predicted = {}\n",
    "label_columns = [\n",
    "    'toxic',\n",
    "    'severe_toxic',\n",
    "    'obscene',\n",
    "    'threat',\n",
    "    'insult',\n",
    "    'identity_hate',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ee806e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit = pipeline.fit(train)\n",
    "train_df = pipelineFit.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "51cd3ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pipelineFit.transform(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5d586e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing toxic\n",
      "Processing severe_toxic\n",
      "Processing obscene\n",
      "Processing threat\n",
      "Processing insult\n",
      "Processing identity_hate\n"
     ]
    }
   ],
   "source": [
    "for col in label_columns:\n",
    "    print(f'Processing {col}')\n",
    "    lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0,\n",
    "                            featuresCol='features', labelCol=col, predictionCol=f'{col}_pred', \n",
    "                            rawPredictionCol=f'raw_{col}_pred', probabilityCol=f'{col}_prob')\n",
    "    lrModel = lr.fit(train_df)\n",
    "\n",
    "    test_df = lrModel.transform(test_df)\n",
    "    predicted[col] = test_df\n",
    "    all_models[col] = lrModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e11081c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "77bbf1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in label_columns:\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=f'raw_{col}_pred', labelCol=col)\n",
    "    metrics[col] = evaluator.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e98c03b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxic': 0.8289137931601808,\n",
       " 'severe_toxic': 0.8579595272474665,\n",
       " 'obscene': 0.8361701492190003,\n",
       " 'threat': 0.9138637279663775,\n",
       " 'insult': 0.8342956917328159,\n",
       " 'identity_hate': 0.8491797229781038}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2a3a3439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|summary|toxic_pred           |severe_toxic_pred   |obscene_pred        |threat_pred         |insult_pred         |identity_hate_pred  |\n",
      "+-------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|count  |63978                |63978               |63978               |63978               |63978               |63978               |\n",
      "|mean   |0.0014848854293663446|1.71934102347682E-4 |8.440401387977117E-4|3.126074588139673E-5|7.502579011535215E-4|9.378223764419019E-5|\n",
      "|stddev |0.03850589201460077  |0.013111339671681745|0.029040332587194247|0.005591087305403376|0.027380773042978507|0.009683744537774713|\n",
      "|min    |0.0                  |0.0                 |0.0                 |0.0                 |0.0                 |0.0                 |\n",
      "|max    |1.0                  |1.0                 |1.0                 |1.0                 |1.0                 |1.0                 |\n",
      "+-------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.select(*pred_cols).describe().show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33981318",
   "metadata": {},
   "source": [
    "##### Делаем вывод, что чем больше numFeatures, тем больше качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd5daad",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4843d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b57b3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(inputCol=\"filtered\", outputCol=\"features\", vectorSize=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2560122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, w2v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "12a7676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {}\n",
    "predicted = {}\n",
    "label_columns = [\n",
    "    'toxic',\n",
    "    'severe_toxic',\n",
    "    'obscene',\n",
    "    'threat',\n",
    "    'insult',\n",
    "    'identity_hate',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f2a78dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit = pipeline.fit(train)\n",
    "train_df = pipelineFit.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a91c7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pipelineFit.transform(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "01db2f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing toxic\n",
      "Processing severe_toxic\n",
      "Processing obscene\n",
      "Processing threat\n",
      "Processing insult\n",
      "Processing identity_hate\n"
     ]
    }
   ],
   "source": [
    "for col in label_columns:\n",
    "    print(f'Processing {col}')\n",
    "    lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0,\n",
    "                            featuresCol='features', labelCol=col, predictionCol=f'{col}_pred', \n",
    "                            rawPredictionCol=f'raw_{col}_pred', probabilityCol=f'{col}_prob')\n",
    "    lrModel = lr.fit(train_df)\n",
    "\n",
    "    test_df = lrModel.transform(test_df)\n",
    "    predicted[col] = test_df\n",
    "    all_models[col] = lrModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e8038680",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c23d980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in label_columns:\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=f'raw_{col}_pred', labelCol=col)\n",
    "    metrics[col] = evaluator.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "01297fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxic': 0.9325592478108421,\n",
       " 'severe_toxic': 0.9704686227858818,\n",
       " 'obscene': 0.9481559391987501,\n",
       " 'threat': 0.9521529692258611,\n",
       " 'insult': 0.9411520293236308,\n",
       " 'identity_hate': 0.9506073895416445}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a1c5ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465adcce",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d18778",
   "metadata": {},
   "source": [
    "##### HashigTF (100)\n",
    "'toxic': 0.7541931801265525    \n",
    "'severe_toxic': 0.8575037811781477    \n",
    "'obscene': 0.7582951685942847    \n",
    "'threat': 0.8149224698894523    \n",
    "'insult': 0.754035473968106    \n",
    "'identity_hate': 0.748578045452460    \n",
    "\n",
    "##### HashigTF(1000)\n",
    "'toxic': 0.8289137931601808    \n",
    "'severe_toxic': 0.8579595272474665    \n",
    "'obscene': 0.8361701492190003    \n",
    "'threat': 0.9138637279663775    \n",
    "'insult': 0.8342956917328159    \n",
    "'identity_hate': 0.849179722978103    \n",
    "\n",
    "#### Word2Vec\n",
    "'toxic': 0.9325592478108421   \n",
    "'severe_toxic': 0.9704686227858818  \n",
    "'obscene': 0.9481559391987501  \n",
    "'threat': 0.9521529692258611  \n",
    "'insult': 0.9411520293236308   \n",
    "'identity_hate': 0.9506073895416445  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a5d3a1",
   "metadata": {},
   "source": [
    "Используя word2vec удалось достичь большего качества, хотя по времени обучение происходило дольше. Если поиграться с настройками HashingTF и попробовать на большем numFeatures, возможно удалось бы достичь приближенного результата."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
